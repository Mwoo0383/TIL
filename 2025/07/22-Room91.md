# ğŸ  Room91 í”„ë¡œì íŠ¸

## ì¬ê°œë°œ AIë‰´ìŠ¤ ì‘ì—…

### 1. ë„¤ì´ë²„, êµ¬ê¸€ ë°ì´í„° í¬ë¡¤ë§í•˜ê¸°

- íŒ¨í‚¤ì§€ ì„¤ì¹˜  
```pip install selenium webdriver-manager pandas```
- í•µì‹¬ì€ CSS SELECTORë¥¼ ì˜ ì§€ì •í•´ì•¼í•¨
```python
def crawl_google_news_selenium(keyword, max_results=10):
    driver = init_driver()
    url = f"https://www.google.com/search?q={keyword}+ì¬ê°œë°œ&hl=ko&tbm=nws"
    driver.get(url)

    try:
        WebDriverWait(driver, 10).until(
            EC.presence_of_element_located((By.CSS_SELECTOR, "div.SoaBEf"))
        )
    except:
        print("âŒ êµ¬ê¸€ ë‰´ìŠ¤ ë¡œë”© ì‹¤íŒ¨ (ìš”ì†Œ íƒìƒ‰ ì‹¤íŒ¨)")
        driver.quit()
        return pd.DataFrame()

    articles = driver.find_elements(By.CSS_SELECTOR, "div.SoaBEf")
    print(f"ğŸ” êµ¬ê¸€ ë‰´ìŠ¤ ê¸°ì‚¬ ìˆ˜: {len(articles)}")
    data = []

    for article in articles[:max_results]:
        try:
            title_tag = article.find_element(By.CSS_SELECTOR, 'div[role="heading"]')
            title = title_tag.text.strip()
            link = article.find_element(By.TAG_NAME, "a").get_attribute("href")
            snippet = article.find_element(By.CSS_SELECTOR, "div:nth-child(3)").text.strip()
            data.append({
                "ì œëª©": title,
                "ë§í¬": link,
                "ìš”ì•½": snippet,
                "ì •ë³´_ì›ì²œ": "Google",
                "í¬ë¡¤ë§_ì‹œê°„": datetime.now()
            })
        except Exception as e:
            print("âŒ êµ¬ê¸€ ë‰´ìŠ¤ íŒŒì‹± ì‹¤íŒ¨:", e)
            continue

    driver.quit()
    return pd.DataFrame(data)
```
```python
def crawl_naver_news_selenium(keyword, max_results=10):
    driver = init_driver()
    url = f"https://search.naver.com/search.naver?where=news&query={keyword}+ì¬ê°œë°œ"
    driver.get(url)

    try:
        WebDriverWait(driver, 10).until(
            EC.presence_of_all_elements_located(
                (By.CSS_SELECTOR, "span.sds-comps-text-type-headline1"))
        )
    except:
        print("âŒ ë„¤ì´ë²„ ë‰´ìŠ¤ ë¡œë”© ì‹¤íŒ¨ (ìš”ì†Œ íƒìƒ‰ ì‹¤íŒ¨)")
        driver.quit()
        return pd.DataFrame()

    titles = driver.find_elements(By.CSS_SELECTOR, "span.sds-comps-text-type-headline1")
    bodies = driver.find_elements(By.CSS_SELECTOR, "span.sds-comps-text-type-body1")
    links = driver.find_elements(By.CSS_SELECTOR, "a[href^='https://']")

    print(f"ğŸ” ë„¤ì´ë²„ ë‰´ìŠ¤ ì œëª© ìˆ˜: {len(titles)}")

    data = []
    for i in range(min(max_results, len(titles))):
        try:
            title = titles[i].text.strip()
            snippet = bodies[i].text.strip() if i < len(bodies) else ""
            link = links[i].get_attribute("href")
            data.append({
                "ì œëª©": title,
                "ë§í¬": link,
                "ìš”ì•½": snippet,
                "ì •ë³´_ì›ì²œ": "Naver",
                "í¬ë¡¤ë§_ì‹œê°„": datetime.now()
            })
        except Exception as e:
            print("âŒ ë„¤ì´ë²„ ë‰´ìŠ¤ íŒŒì‹± ì‹¤íŒ¨:", e)
            continue

    driver.quit()
    return pd.DataFrame(data)
```